# Test
# TinyWebServer
# 1、项目的重点、难点，以及怎么解决难点的
项目的重点 ：在于应用层上 HTTP 协议的使用，怎么去解析 HTTP请求，怎么根据 HTTP 请求去做出应答这样一个流程我觉得是这个项目的重点。
项目的难点 ：我觉得在于如何将一个完整的服务器拆分成多个模块，同时在实现的时候又将其各个部分功能组合在一起。首先一个 HTTP服务器要实现的是完成请求应答这样一件事，然后需要考虑到读写数据的缓冲区、同时多个连接需要处理多种事件、连接超时关闭避免资源消耗等这一系列问题，所以就有了各种模块。单独编写模块出来后还要考虑怎么去组合怎么去搭配，互相之间的接口要怎么设计，我觉得是我在项目中遇到的问题。
难点的解决 ：通过自顶向下的设计方式。先确定整体的功能也就是完成一次 HTTP 传输，再向下考虑需要用到什么组件，然后再依次实现各个组件，最后再将模块组合起来，期间需要多次修改接口。

# 2、项目实现的效果以及瓶颈和不足
项目实现效果我是部署在本机上的，跑过压力测试但是实际效果并不理想，只有7000左右的QPS（并发数/平均访问时间），拆测可能跟设计模式的选择还有测试服务器的性能有关系。
该服务器的瓶颈我觉得在于网络设计模式的选择。首先该服务器的网络设计模式是采用的单Reactor多线程模式。就是主线程内循环使用IO多路复用，监听连接并且建立连接，同时也会监听新连接上的读写事件，并将读写和业务逻辑处理分发给多线程进行处理。这么一个设计模式的缺陷在于一个Reactor对象承担了所有事件的监听和响应，当遇到突发的高并发时，往往不能及时处理新连接。

# 3、针对瓶颈如何改进
针对不足可以改变网络设计模式。即采用多Reactor多线程模型。相比改变前，多Reactor多线程模型中主线程主Reactor只负责监听连接还有建立连接，并且将建立好的连接通过生产者消费者模型传递给子线程里的子Reactor负责监听对应连接上的事件。这样主线程就可以在遇到瞬间并发时也能够及时处理新连接的建立。

# 4、采用什么网络模型
采用单Reactor多线程模型。主线程是一个Reactor，进行IO多路复用实现连接事件和读写事件的监听，同时主线程负责新连接的建立，子线程则负责数据的读写还有业务逻辑处理。

# 5、HTTP解析怎么实现的（正则表达式和有限状态机）
HTTP解析是通过正则表达式还有有限状态机实现的。一个HTTP请求报文是由三部分组成的，请求行、头部字段还有消息体，通过在状态机里重复这三个部分之间的解析跳转，最终可以完成一个完整请求报文的解析。HTTP1.1请求报文是ASCII码的固定文本形式，通过正则表达式去解析可以简化我们的任务量。

# 6、HTTP应答怎么将网页资源发送出去
HTTP应答发送这里采用了集中写的形式。利用Linux函数writev，我们可以根据解析结果制作响应行和响应头并且存放在缓冲区，然后将响应体（也就是请求的资源文件）通过内存映射mmap映射到我们内存中去，最后通过集中写的形式将一个完整的HTTP应答发送出去。

# 7、主机字节序和网络字节序
主机字节序通常指的是小端序，而网络字节序通常指的是大端序。所谓的小端序指的就是整数的低位字节存放在内存的低地址处，而大端序则指的是整数的高位字节存放在内存的低地址处。之所以要进行转换是为了数据传输的统一。

# 8、浏览器从输入URL到显示的整个过程
主要有过程：URL输入之后，需要建立TCP连接，而一个唯一确认的TCP连接需要一个四元组（服务器IP，服务器端口，客户端IP，客户端端口）确定。而此时客户端并不知道域名所对应的IP地址，所以此时需要通过DNS域名服务器进行解析，将域名转换为对应的服务器IP地址。这个时候客户端就可以建立和服务器之间的TCP连接了（这个中间有三次握手的流程）。连接之后客户端请求服务器的数据需要发送HTTP请求到达服务器端，接着服务器进行响应，并且发送回资源。浏览器在接到资源之后对其进行解析并渲染，对于网页中的其他资源会再次发送HTTP请求该资源，直到网页内容完整的传输到浏览器。

# 9、线程池及其线程数量
这个项目实现一个固定线程数量的线程池。使用到了生产者消费者模型，所有线程共享一个生产队列，通过条件变量唤醒线程执行队列里的任务。所有线程是分离状态，在线程池销毁的时候设置关闭标志位，唤醒所有线程使其退出。
线程池数量是对外开放接口，由调用者自定义，在运行时会固定线程数量不会发生动态调整。

# 10、epoll
epoll是Linux上独有的IO多路复用技术。一个进程可以监视多个描述符，epoll所支持的文件描述符上限是最大可以打开文件的数目，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的。epoll底层是一棵红黑树还有一个双向链表，红黑树存放的是与文件描述符相对应的epitem结构体，当文件描述符上有对应感兴趣事件发生时，内核将其添加到链表里，每次epoll_wait则【清空链表（ET模式下）】将其拷贝到用户空间，同时返回就绪事件的数量。使用红黑树查找删除添加都是logn的时间复杂度，有较稳定的时间复杂度，同时红黑树查找是为了防止重复添加文件描述符。

# 11、select、poll和epoll的区别？三者的应用场景
![image](https://user-images.githubusercontent.com/75972398/222871687-fe835cb3-c343-4cea-8ba2-24e59b01dc4c.png)
当有事件触发时，select和poll需要用户自己去遍历文件描述符找出触发的事件，而epoll能够直接返回所有的触发事件；
每次调用select和poll都需要将文件描述符集合拷贝到内核空间，返回时再拷贝一次。而epoll只需要拷贝需要修改的文件描述符而不需要集体的拷贝；
select支持的文件描述符数量有上限，而poll和epoll没有此限制；

# 12、epoll一定高效嘛？为什么要用epoll
epoll适用于需要观察大量事件的场景；select能够监听的事件数量有最大文件描述符的上限，一般是1024个，而且每次调用时都需要将文件描述符集合在内核和用户之间进行拷贝。poll没有文件描述符数量的限制，不过和select一样，每次调用都要将文件描述符集合在内核和用户之间进行拷贝，每次有事件触发时，需要遍历所有文件描述符找出触发的事件；而epoll只需要往内核空间里的红黑树添加修改或者删除指定的文件描述符和事件，不需要每次都拷贝所有的文件描述符集合到内核当中去，同时也能够直接返回就绪事件无需重复遍历文件描述符集合。

所以在需要监听多个文件描述符上的事件的时候，选用epoll更有效率，内核直接返回触发事件。但是当需要监听的文件描述符数量少且较为活跃的情况下，select和poll相比epoll更有效率，因为其省去了触发感兴趣事件时的函数回调操作（将数据从红黑树上添加到就绪链表中）。

# 13、LT模式和ET模式的区别
LT模式下只要内核缓冲区还有数据可读便会提醒（哪怕已经提醒过，针对同一事件可以多次提醒）

ET模式下，每一次事件到来只通知一次（针对一个事件只提醒一次而不是提醒多次），没有及时读取完，该部分剩余数据直到下次触发，才能被读取（有可能永远也读不到，如果没有再次触发文件描述符上的该事件）
